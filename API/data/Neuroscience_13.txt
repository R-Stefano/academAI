Sort by color Sort by shape Sort by number Long before PET scanning and functional MRI were used to evaluate normal and abnormal cognitive function, several "low-tech" methods proved to be reliable means of assessing these abilities in human subjects. From the late 1940s onward, psychologists and neurologists developed a battery of behavioral testsgenerally called neuropsychological tests-to evaluate the integrity of cognitive function and to help localize lesions.One of the most frequently used measures is the Wisconsin Card Sorting Task illustrated here. In this test, the examiner places four cards with symbols that differ in number, shape, or color before the subject, who is given a set of response cards with similar symbols on them. The subject is then asked to place an appropriate response card in front of the stimulus card based on a sorting rule established, but not stated, by the examiner. The examiner then indicates whether the response is "right" or "wrong." After 10 consecutive correct responses, the examiner changes the sorting rule simply by saying "wrong." The subject must then ascertain the new sorting rule and perform 10 correct trials. The sorting rule is then changed again, until six cycles have been completed.In 1963, the neuropsychologist Brenda Milner at the Montreal Neurological Institute showed that patients with frontal lobe lesions have consistently poor performance in the Wisconsin Card Sorting Task. By comparing patients with known brain lesions as a result of surgery for epilepsy or tumor, Milner was able to demonstrate that this impairment is fairly specific for frontal lobe damage. Particularly striking is the inability of frontal lobe patients to use previous information to guide subsequent behavior. A widely accepted explanation for the sensitivity of the Wisconsin Card Sorting Task to frontal lobe deficits is the "planning" aspect of this test. To respond correctly, the subject must retain information about the previous trial, which is then used to guide behavior on future trials. Processing this sort of information is characteristic of frontal lobe function.A variety of other neuropsychological tests have been devised to evaluate the functional integrity of other cognitive functions. These include tasks in which a patient is asked to identify familiar faces in a series of pictures, and others in which "distractors" interfere with the patients ability to attend to salient stimulus features. An example of the latter is the Stroop Interference Test, in which patients are asked to read the names of colors presented in color-conflicting print clinical evaluation of frontal lobe function in humans. In the delayed response task, the monkey watches an experimenter place a food morsel in one of two wells both wells are then covered. Subsequently, a screen is lowered for an interval of a few seconds to several minutes. When the screen is raised, the monkey gets only one chance to uncover the well containing food and receive the reward. Thus, the animal must decide that he wants the food, remember where it is placed, recall that the cover must be removed to obtain the food, and keep all this information available during the delay so that it can be used to get the reward. The monkeys ability to carry out this task is diminished or abolished if the area anterior to the motor region of the frontal cortex-called the prefrontal cortex-is destroyed bilaterally.Some neurons in the prefrontal cortex, particularly those in and around the principal sulcus In addition to maintaining cognitive information during short delays, some neurons in prefrontal cortex also appear to participate directly in longer range planning of sequences of movements. When monkeys are trained to perform a motor sequence, such as turning a joystick to the left, then right, then left again, some neurons in prefrontal cortex fire at a particular point in the sequence, regardless of which movement is made. Prefrontal neurons have also been found that are selective for each position in a learned motor sequence, thus ruling out the possibility that these neurons merely encode task difficulty or proximity to reward as the monkey nears the end of the series of responses. Similar neurons have been found in the supplementary eye field in pre-The Association Cortices 633. This sort of challenge evaluates both attention and identification abilities.The simplicity, economy, and accumulated experience with such tests continue to make them a valuable means of evaluating cognitive functions.The fact that so much of the brain is occupied by the association cortices raises a fundamental question: does more of it provide individuals with greater cognitive ability Humans and other animals obviously vary in their talents and predispositions for a wide range of cognitive behaviors. Does a particular talent imply a greater amount of neural space in the service of that functionHistorically, the most popular approach to the issue of brain size and behavior in humans has been to relate the overall size of the brain to a broad index of performance, conventionally measured in humans by "intelligence tests." This way of studying the relationship between brain and behavior has caused considerable trouble. In general terms, the idea that the size of brains from different species reflects intelligence represents a simple and apparently valid idea Nineteenth-century enthusiasm for brain size as a simple measure of human performance was championed by some remarkably astute scientists, as well as others whose motives and methods are now suspect There are at least two reasons why measures such as brain weight or cranial capacity are not easily interpretable indices of intelligence, even though small observed differences may be statistically valid. First is the obvious difficulty of defining and accurately measuring intelligence , particularly among humans with different educational and cultural backgrounds. Second is the functional diversity and connectional complexity of frontal cortex that are selective for particular sequences of eye movements. When these regions of prefrontal cortex are inactivated pharmacologically, monkeys lose the ability to execute sequences of movements from memory. These further observations endorse the notion, first inferred from studies of individuals like Phineas Gage, that the frontal lobe contributes specifically to the cognitive functions that use stored information to plan and guide appropriate behavior.In short, the existence of planning-specific neurons in the frontal cortex of rhesus monkeys, as well as attention-specific cells in the parietal cortex and recognition-specific cells in the temporal cortex, supports the functions of these cortical areas inferred from clinical evidence in humans. Nonetheless, functional localization, whether inferred by examining human patients or by recording single neurons in monkeys, is an imprecise business. The observations summarized here are only a rudimentary guide to thinking about how complex cognitive information is represented and processed in the brain, and how the relevant brain areas and their constituent neurons contribute to such important but still ill-defined qualities as personality, intelligence, or other cognitive functions that define what it means to be a human being.The majority of the human cerebral cortex is devoted to tasks that transcend encoding primary sensations or commanding motor actions. Collectively, the association cortices mediate these cognitive functions of the brain-broadly defined as the ability to attend to, identify, and act meaningfully in responseThe Association Cortices 635 the brain. Imagine assessing the relationship between body size and athletic ability, which might be considered the somatic analogue of intelligence. Body weight, or any other global measure of somatic phenotype, would be a woefully inadequate index of athletic ability. Although the evidence would presumably indicate that bigger is better in the context of sumo wrestling or basketball, more subtle somatic features would no doubt be correlated with extraordinary ability in Ping-Pong, gymnastics, or figure skating. The diversity of somatic function vis--vis athletic ability confounds the interpretation of any simple measure such as body size.The implications of this analogy for the brain are straightforward. Any program that seeks to relate brain weight, cranial capacity, or some other measure of overall brain size to individual performance ignores the reality of the brains functional diversity. Thus, quite apart from the political or ethical probity of attempts to measure "intelligence" by brain size, by the yardstick of modern neuroscience, this approach will inevitably generate more heat than light. A more rational approach to the issue has become feasible in the last few years, which is to relate the size of measurable regions of known function to the corresponding functions, as well as to cellular features such as synaptic density and dendritic arborization. These correlations have greater promise for exploring the sensible idea that better performance will always be based on more underlying neural machinery.636 Chapter Twenty-Five to complex external or internal stimuli. Descriptions of patients with cortical lesions, functional brain imaging of normal subjects, and behavioral and electrophysiological studies of non-human primates have established the general purpose of the major association areas. Thus, parietal association cortex is involved in attention and awareness of the body and the stimuli that act on it temporal association cortex is involved in the recognition and identification of highly processed sensory information and frontal association cortex is importantly involved in guiding complex behavior by planning responses to ongoing stimulation, matching such behaviors to the demands of a particular situation. More than any other brain regions, the association areas support the mental processes that make us human.One of the most remarkable cortical functions in humans is the ability to associate arbitrary symbols with specific meanings to express thoughts and emotions to ourselves and others by means of written and spoken language. Indeed, the achievements of human culture rest largely upon this kind of communication, and a person who for one reason or another fails to develop a facility for language as a child is severely incapacitated. Studies of patients with damage to specific cortical regions and normal subjects studied by functional brain imaging indicate that linguistic abilities of humans depend on the integrity of several specialized areas of the association cortices in the temporal and frontal lobes. In the vast majority of people, these primary language functions are located in the left hemisphere: the linkages between speech sounds and their meanings are mainly represented in the left temporal cortex, and the circuitry for the motor commands that organize the production of meaningful speech is mainly found in the left frontal cortex. Despite this left-sided predominance for the "lexical" aspects of language, the emotional content of speech is governed largely by the right hemisphere. Studies of congenitally deaf individuals have shown further that the cortical areas devoted to sign language are the same as those that organize spoken and heard communication. The regions of the brain devoted to language are therefore specialized for symbolic representation and communication, rather than for heard and spoken language as such. Understanding functional localization and hemispheric lateralization of language is especially important in clinical practice. The loss of language is such a devastating blow that neurologists and neurosurgeons make every effort to identify and preserve those cortical areas involved in its comprehension and production. The need to map language functions in patients for the purpose of sparing these regions of the brain has provided another rich source of information about the neural organization of this critical human attribute.It has been known for more than a century that two regions in the frontal and temporal association cortices of the left cerebral hemisphere are especially important for normal human language. That language abilities are both localized and lateralized is not surprising ample evidence of the localization and lateralization of other cognitive functions was reviewed in Chapter 25. The unequal representation of language functions in the two cerebral hemispheres provides an especially compelling example of this phenomenon.Although the concept of lateralization has already been introduced in describing the unequal functions of the parietal lobes in attention and of the temporal lobes in recognizing different categories of objects, it is in language that this idea has been most thoroughly documented. Because language is so important to human beings, its lateralization has given rise to the misleading idea that one hemisphere in humans is actually "dominant" over the othernamely, the hemisphere in which the major capacity for language resides. The true significance of lateralization for language or any other cognitive ability, however, lies in the efficient subdivision of complex functions between the hemispheres, rather than in any superiority of one hemisphere over the other. Indeed, pop psychological dogmas about cortical redundancy notwithstanding, it is a safe presumption is that every region of the brain is doing something important.A first step in the proper consideration of these issues is recognizing that the cortical representation of language is distinct from the circuitry concerned with the motor control of the larynx, pharynx, mouth, and tonguethe structures that produce speech sounds. Cortical representation is also distinct from, although clearly related to, the circuits underlying the auditory perception of spoken words and the visual perception of written words in the primary auditory and visual cortices, respectively Given the profound biological and social importance of communication among the members of a species, it is not surprising that other animals communicate in ways that, while grossly impoverished compared to human language, nonetheless suggest the sorts of communicative skills and interactions from which human language evolved in the brains of our prehominid ancestors.The distinction between language and the related sensory and motor capacities on which it depends was first apparent in patients with damage to specific brain regions. Clinical evidence of this sort showed that the ability to move the muscles of the larynx, pharynx, mouth, and tongue can be compromised without abolishing the ability to use spoken language to communicate. Similarly, damage to the auditory pathways can impede the ability to hear without interfering with language functions per se. Damage to specific brain regions, however, can compromise essential language functions while leaving the sensory and motor infrastructure of verbal communication intact. These syndromes, collectively referred to as aphasias, diminish or abolish the ability to comprehend andor to produce language, while sparing the ability to perceive the relevant stimuli and to produce intelligible words. Missing in these patients is the capacity to recognize or employ the symbolic value of words, thus depriving such individuals of the linguistic understanding, grammatical and syntactical organization, and appropriate intonation that distinguishes language from nonsense.The localization of language function to a specific region of the cerebrum is usually attributed to the French neurologist Paul Broca and the German neurologist Carl Wernicke, who made their seminal observations in the late 1800s. Both Broca and Wernicke examined the brains of individuals who had become aphasic and later died. Based on correlations of the clinical picture and the location of the brain damage, Broca suggested that language abilities were localized in the ventroposterior region of the frontal lobe Although Broca was basically correct, he failed to grasp the limitations of thinking about language as a unitary function localized in a single cortical region. This issue was better appreciated by Wernicke, who distinguished between patients who had lost the ability to comprehend language and those who could no longer produce language. Wernicke recognized that some aphasic patients do not understand language but retain the ability to produce utterances with reasonable grammatical and emotional content. He concluded that lesions of the posterior and superior temporal lobe on the left side tend to result in a deficit of this sort. In contrast, other patients continue to comprehend language but lack the ability to organize or control the linguistic content of their response. Thus, they produce nonsense syllables, transposed words, and utter grammatically incomprehensible phrases. These deficits are associated with damage to the posterior and inferior region of the left frontal lobe, an area that Broca emphasized as an important substrate for language The organs that produce speech include the lungs, which serve as a reservoir of air the larynx, which is the source of the periodic stimulus quality of "voiced" sounds and the pharynx, oral, and nasal cavities and their included structures, which modify the speech sounds that eventually emanate from the speaker. The fundamentally correct idea that the larynx is the "source" of speech sounds and the rest of the vocal tract acts as a filter that modulates the sound energy of the source is an old one, having been proposed by Johannes Mueller in the nineteenth century.Although the physiological details are complex, the general operation of the vocal apparatus is simple. Air expelled from the lungs accelerates as it passes through a constricted opening between the vocal folds called the glottis, thus decreasing the pressure in the air stream. As a result, the vocal folds come together until the pressure buildup in the lungs forces them open again. The ongoing repetition of this process results in an oscillation of sound wave pressure, the frequency of which is determined primarily by the muscles that control the tension on the vocal cords. The frequencies of these oscillations-which are the basis of voiced speech sounds-range from about 100 to about 400 Hz, depending on the gender, size, and age of the speaker.The larynx has many other consequential effects on the speech signal that create additional speech sounds. For instance, the vocal folds can open suddenly to produce what is called a glottal stop. Alternatively, the vocal folds can hold an intermediate position for the production of consonants such as h, or they can be completely open for "unvoiced" consonants such as s or f. In short, the larynx is important in the production of virtually all vocal sounds.The vocal system can be thought of as a sort of musical instrument capable of extraordinary subtlety and exquisite modulation. As in the sound produced by a musical instrument, however, the primary source of oscillation is hardly the whole story. The entire pathway between the vocal folds and the lips is equally critical in determining speech sounds, as is the structure of a musical instrument. The key determinants of the sound that emanates from an instrument are its natural resonances, which shape or filter the sound pressure oscillation. For the vocal tract, the resonances that modulate the air stream generated by the larynx are called formants. aphasia, also known as Brocas aphasia. The deficient motor-planning aspects of expressive aphasias accord with the complex motor functions of quency of the major formant arises from the fact that the approximate length of the vocal tract is 17 cm, which is the quarter wavelength of a 68-cm sound wave quarter wavelengths determine the resonances of pipes open at one end, which is essentially what the vocal tract is. Since the speed of sound is about 33,500 cmsec, the lowest resonance frequency of an open tube or pipe of this length will be 33,50068 or about 500 Hz additional resonant frequencies will occur at the odd harmonics of this major formant. The result of these physical facts about the vocal tract is that any power in the laryngeal source at these formant frequencies will be reinforced, and any other power will, in varying degrees, be filtered out. Of course, this general statement is conplicated by the further fact that the shape of the vocal tract changes to produce different speech sounds. Thus, in addition to the effects of the larynx, specific speech sounds are generated by dynamic effects imposed by the configuration of the rest of the vocal tract.In any given language, the basic speech sounds are called phonemes. Phonemes are used to make up syllables, which are used in turn to make up words, which are used to create sentences. There are about 40 phonemes in English, and these are about equally divided between vowel and consonant speech sounds. Vowel sounds are by and large the voiced elements of speech. In contrast, consonant sounds involve rapid changes in the sound signal and are more complex. In English, consonants begin andor end syllables, each of which entails a vowel sound. Consonant sounds are categorized according to the site in the vocal tract that determines them, or the physical way they are generated. With respect to place, there are labial consonants, dental consonants, palatal consonants, and glottal consonants. With respect to manner, there are plosive, fricative, nasal, liquid, and semivowel consonants. Plosives are produced by blocking the flow of air somewhere in the vocal tract, fricatives by producing turbulence, nasals by directing the flow of air through the nose, and so on.A further variation on the use of consonants is found in the "click languages" of southern Africa, of which about 30 survive today. Each of these languages has 4-5 different click sounds that are double consonants made by sucking the tongue down from the roof of the mouth.It should be obvious then that speech stimuli are enormously complex. To make matters worse, Alvin Liberman, working at the Haskins Laboratory at Yale University, showed that there is no one-to-one correspondence between phonemes and phones. Because speech sounds changes continuously, they cannot be split up into discrete segments, as the concept of phonemes implies. This fact is now recognized as a fundamental problem that undermines any strictly phonemic approach to language. Moreover, the phones for different vowels overlap in natural speech of men, women, and children. Evidence from studies of illiterates suggests that phonemes are probably more related to learning how to read and spell than to actually hearing speech, implying that syllables or words are much better candidates for the natural units of speech perception.Given this complexity, it is remarkable that we can communicate so readily. A clue to the obvious success of humans in this task is computer-based speech recognition programs. These programs achieve the very substantial success they currently enjoy by virtue of prolonged empirical training rather than in the a priori application of any logical rules. Over the centuries, theologians, natural philosophers, and a good many modern neuroscientists have argued that language is uniquely human, this extraordinary behavior being seen as setting us qualitatively apart from our fellow animals. However, the gradual accumulation of evidence during the last 75 years demonstrating highly sophisticated systems of communication in species as diverse as bees, birds, monkeys, and whales has made this point of view increasingly untenable, at least in a broad sense. Until recently, however, human language has appeared unique in the ability to associate specific meanings with arbitrary symbols, ad infinitum. In the dance of the honeybee described so beautifully by Karl von Frisch, for example, each symbolic movement made by a foraging bee that returns to the hive encodes only a single meaning, whose expression and appreciation has been hardwired into the nervous systems of the actor and the respondents.A series of controversial studies in great apes, however, have indicated that the rudiments of the human symbolic communication are evident in the behavior of our closest relatives. Although early efforts were sometimes patently misguided, modern work on this issue has shown that if chimpanzees are given the means to communicate symbolically, they demonstrate some surprising talents. While techniques have varied, most psychologists who study chimps have used some form of manipulable symbols that can be arranged to express ideas in an interpretable manner.For example, chimps can be trained to manipulate tiles or other symbols to represent words and syntactical constructs, allowing them to communicate simple demands, questions, and even spontaneous expressions. The most remarkable results have come from increasingly sophisticated work with chimps using keyboards with a variety of symbols Given the challenge this work presents to some long-held beliefs about the uniqueness of human language, it is not surprising that these claims continue to stir up debate and are not universally accepted. Nonetheless, the issues raised certainly deserve careful consideration by anyone interested in human language abilities and how our remarkable symbolic skills may have evolved from the communicative capabilities of our ancestors. The pressure for the evolution of some form of symbolic communication in great apes seems clear enough. Ethologists studying chimpanzees in the wild have described extensive social communication based on gestures, the manipulation of objects, and facial expressions. This intricate social intercourse is likely to be the antecedent of human language one need only think of the importance of gestures and facial expressions as ancillary aspects of our own speech to appreciate this point.Whether the regions of the temporal, parietal, and frontal cortices that support human language also serve these sym-  The second rule is that damage to the left temporal lobe causes difficulty understanding spoken language, a deficiency referred to as sensory or receptive aphasia, also known as Wernickes aphasia. Receptive aphasia generally reflects damage to the auditory association cortices in the posterior temporal lobe, a region referred to as Wernickes area.A final broad category of language deficiency syndromes is conduction aphasia. These disorders arise from lesions to the pathways connecting the relevant temporal and frontal regions, such as the arcuate fasciculus in the subcortical white matter that links Brocas and Wernickes areas. Interruption of this pathway may result in an inability to produce appropriate responses to heard communication, even though the communication is understood.In a classic Brocas aphasia, the patient cannot express himself appropriately because the organizational aspects of language  have been disrupted, as shown in the following example reported by Howard Gardner. The patient was a 39-year-old Coast Guard radio operator named Ford who had suffered a stroke that affected his left posterior frontal lobe.I am a signomanuh, well,again. These words were emitted slowly, and with great effort. The sounds were not clearly articulated each syllable as uttered harshly, explosively, in a throaty voice. With practice, it was possible to understand him, but at first I encountered considerable difficulty in this. Let me help you, I interjected. You were a signal A sig-nal manright, Ford completed my phrase triumphantly. Were you in the Coast Guard No, er, yes, yes, shipMassachuchusettsCoastguard years. He raised his hands twice, indicating the number nineteen. Oh, you were in the Coast Guard for nineteen years. Ohboyrightright, he replied. Why are you in the hospital, Mr. Ford Ford looked at me strangely, as if to say, Isnt it patently obvious He pointed to his paralyzed arm and said, Arm no good, then to his mouth and said, Speechcant saytalk, you see.Howard Boy, Im sweating, Im awful nervous, you know, once in a while I get caught up, I cant get caught up, I cant mention the tarripoi, a month ago, quite a little, Ive done a lot well, I impose a lot, while, on the other hand, you know what I mean, I have to run around, look it over, trebbin and all that sort of stuff. Oh sure, go ahead, any old think you want. If I could I would. Oh, Im taking the word the wrong way to say, all of the barbers here whenever they stop you its going around and around, if you know what I mean, that is tying and tying for repucer, repuceration, well, we were trying the best that we could while another time it was with the beds over there the same thing Ibid., p. 68.The major differences between these two classical aphasias are summarized in Despite the validity of Brocas and Wernickes original observations, the classification of language disorders is considerably more complex. An effort to refine the nineteenth-century categorization of aphasias was undertaken Using words appropriately is made even more difficult by the fact that word meanings are continually changing, and by the enormous ambiguity of the words we do use. There is far more to a lexicon-be it a dictionary or a region of the left temporal cortex-than simply attaching meanings to words. Even when the meaning of a word is known, it must be understood in a particular context From the points of view of both neuroscience and linguistics, two related questions about words and grammar are especially germane in relation to this chapter. First, what is the nature of the neural machinery that allows us to learn language And second, why do humans have such a profound drive to learn language The major twentieth-century figure who has grappled with these questions is linguist Noam Chomsky, working at the Massachusetts Institute of Technology. Chomsky, while not interested in brain structure has argued that the complexity of language is such that it cannot simply be learned. He therefore proposed that language must be predicated on a "universal grammar" laid down in the evolution of our species. Although this argument is undoubtedly correct, Chomskys eschewing of neurobiology avoids the central question of how, in evolutionary or developmental terms, this machinery comes to be and how it encodes words and strings them together into meaningful sentences. Whatever the mechanisms eventually prove to be, much of the language we use is obviously learned by making neuronal associations between arbitrary symbols and the objects, concepts, and interrelationships they signify in the real world. As such, human language provides a rich source for understanding how the relevant parts of the human cortex and their constituent neurons work to produce the enormous facility for making associations, which appears to be a fundamental aspect of all cortical functions. The importance of context. When a person says "Im going to our house on the lake," the meaning of the expression obviously depends on usage and context, rather than on the literal structure of the sentence uttered. This example indicates the enormous complexity of the task we all accomplish routinely. How this is done, even in principle, remains a central puzzle in language. Until the 1960s, observations about language localization and lateralization were based primarily on patients with brain lesions of varying severity, location, and etiology. The inevitable uncertainties of clinical findings allowed skeptics to argue that language function might not be lateralized in the brain. Definitive evidence supporting the inferences from neurological observations came from studies of patients whose corpus callosum and anterior commissure had been severed as a treatment for medically intractable epileptic seizures.. In such patients, investigators could assess the function of the two cerebral hemispheres independently, since the major axon tracts that connect them had been interrupted. The first studies of these so-called split-brain patients were carried out by Roger Sperry and his colleagues at the California Institute of Technology in the 1960s and 1970s, and established the hemispheric lateralization of language beyond any doubt this work also demonstrated many other functional differences between the left and right hemispheres To evaluate the functional capacity of each hemisphere in split-brain patients, it is essential to provide information to one side of the brain only. Sperry, Michael Gazzaniga, and others devised several simple ways to do this, the most straightforward of which was to ask the subject to use each hand independently to identify objects without any visual assistance The ingenious work of Sperry and his colleagues on split-brain patients put an end to the century-long controversy about language lateralization in most individuals, the left hemisphere is unequivocally the seat of the major language functions. It would be wrong to suppose, however, that the right hemisphere has no language capacity. As noted, in some individuals the right hemisphere can produce rudimentary words and phrases, and it is normally the source of emotional coloring of language. Moreover, the right hemisphere in many split-brain patients understands language to a modest degree, since these patients can respond to simple visual commands presented tachistoscopically in the left visual field. Consequently, Brocas conclusion that we speak with our left brain is not strictly correct it would be more accurate to say that we understand language and speak very much better with the left hemisphere than with the right, and thus that the contributions of the two hemispheres to the overall goals of communication are different.The differences in language function between the left and right hemispheres have naturally inspired neurologists and neuropsychologists to find a structural correlate of this behavioral lateralization. One hemispheric difference that has received much attention over the years was identified in the late 1960s by Norman Geschwind and his colleagues at Harvard Medical School, who found an asymmetry in the superior aspect of the temporal lobe known as the planum temporale Because the planum temporale is near the regions of the temporal lobe that contain cortical areas essential to language, it was initially suggested that this leftward asymmetry reflected the greater involvement of the left hemisphere in language. Nonetheless, these anatomical differences in the two hemispheres of the brain, which are recognizable at birth, are unlikely to be an anatomical correlate of the lateralization of language functions. The fact that a detectable planum asymmetry is present in only 67% of human brains, whereas the preeminence of language in the left hemisphere is evident in 97% of the population, argues that this association has some other cause. The structural correlate of the functional left-right differences in hemispheric language abilities, if indeed there is one at a gross anatomical level, is simply not clear, as is the case for the lateralized hemispheric functions described in Chapter 25.The pioneering work of Broca and Wernicke, and later Geschwind and Sperry, clearly established differences in hemispheric function. Several techniques have since been developed that allow hemispheric attributes to be assessed in neurological patients with an intact corpus callosum, and in normal subjects.One method that has long been used for the clinical assessment of language lateralization was devised in the 1960s by Juhn Wada at the Montreal Neurological Institute. In the so-called Wada test, a short-acting anesthetic is injected into the left carotid artery this procedure transiently "anesthetizes" the left hemisphere and thus tests the functional capabilities of the affected half of the brain. If the left hemisphere is indeed "dominant" for language, then the patient becomes transiently aphasic while carrying out an ongoing verbal task like counting. The anesthetic is rapidly diluted by the circulation, but not before its local effects on the hemisphere on the side of the injection can be observed. Since this test is potentially dangerous, its use is limited to neurological and neurosurgical patients. Approximately 9 out of 10 people are right-handed, a proportion that appears to have been stable over thousands of years and across all cultures in which handedness has been examined. Handedness is usually assessed by having individuals answer a series of questions about preferred manual behaviors, such as "Which hand do you use to write" "Which hand do you use to throw a ball" or "Which hand do you use to brush your teeth" Each answer is given a value, depending on the preference indicated, providing a quantitative measure of the inclination toward right-or left-handedness. Anthropologists have determined the incidence of handedness in ancient cultures by examining artifacts the shape of a flint ax, for example, can indicate whether it was made by a right-or left-handed individual. Handedness in antiquity has also been assessed by examining the incidence of figures in artistic representations who are using one hand or the other. Based on this evidence, the human species appears always to have been a right-handed one. Handedness, or its equivalent, is not peculiar to humans many studies have demonstrated paw preference in animals ranging from mice to monkeys that is, at least in some ways, similar to human handedness.Whether an individual is right-or left-handed has a number of interesting consequences. As will be obvious to lefthanders, the world of human artifacts is in many respects a right-handed one Hotly debated in recent years have been the related questions of whether being left-handed is in any sense "pathological," and whether being left-handed entails a diminished life expectancy. No one disputes the fact that there is currently a surprisingly small number of left-handers among the elderly An alternative explanation, however, is that the diminished number of lefthanders among the elderly is primarily a reflection of sociological factors-namely, a greater acceptance of left-handed children today compared to the first half of the twentieth century. In this view, there are fewer older left-handers now because in earlier generations parents, teachers, and other authority figures encouraged right-handedness. The weight of the evidence favors the sociological explanation.The relationship between handedness and other lateralized functionslanguage in particular-has long been a source of confusion. It is unlikely that there is any direct relationship between language and handedness, despite much speculation to the contrary. The most straightforward evidence on this point comes from the results of the Wada test described in the text. The large number of such tests carried out for clinical purposes indicate that about 97% of humans, including the majority of lefthanders, have their major language functions in the left hemisphere. Since most left-handers have language function on the side of the brain opposite the control of their preferred hand, it is hard to argue for any strict relationship between these two lateralized functions. In all likelihood, handedness, like language, is first and foremost an example of the advantage of having any specialized function on one side of the brain or the other to make maximum use of the available neural circuitry in a brain of limited size. Writing techniques for right-and left-handed individuals.The percentage of left-handers in the normal population as a function of age. Taken at face value, these data indicate that right-handers live longer than left-handers. Another possibility, however, is that the paucity of elderly left-handers at present may simply reflect changes over the decades in the social pressures on children to become right-handed. Less invasive ways to test the cognitive abilities of the two hemispheres in normal subjects include positron emission tomography, functional magnetic resonance imaging, and the sort of tachistoscopic presentation used so effectively by Sperry and his colleagues. Application of these various techniques, together with noninvasive brain imaging, has amply confirmed the hemispheric lateralization of language functions. More importantly, such studies have provided valuable diagnostic tools to determine, in preparation for neurosurgery, which hemisphere is "eloquent": although most individuals have the major language functions in the left hemisphere, a few-about 3% of the population-do not.Once the appropriate hemisphere is known by these means, neurosurgeons typically map language functions more precisely by electrical stimulation of the cortex during the surgery to further refine their approach to the problem at hand. By the 1930s, the neurosurgeon Wilder Penfield and his colleagues at the Montreal Neurological Institute had already carried out a detailed localization of cortical capacities in a large number of patients. Penfield used electrical mapping techniques adapted from neurophysiological work in animals to delineate the language areas of the cortex prior to removing brain tissue in the treatment of tumors or epilepsy. Such intraoperative mapping guaranteed that the cure would not be worse than the disease and has been widely used ever since, with increasingly sophisticated stimulation and recording methods. As a result, a wealth of more detailed information about language localization has emerged.Penfields observations, together with more recent studies performed by George Ojemann and his group at the University of Washington, have further advanced the conclusions inferred from postmortem correlations and other approaches. As expected, intraoperative studies using electrophysiological recording methods have shown that a large region of the perisylvian cortex of the left hemisphere is clearly involved in language production and comprehension Finally, Hanna Damasio and her colleagues at the University of Iowa have shown that distinct regions of the temporal cortex are activated by tasks in which subjects named particular people, animals, or tools Because exactly the same cytoarchitectonic areas exist in the cortex of both hemispheres, a puzzling issue remains. What do the comparable areas in the right hemisphere actually do In fact, language deficits often do occur following damage to the right hemisphere. The most obvious effect of such lesions is an absence of the normal emotional and tonal components of language-called prosodic elements-that impart additional meaning to verbal communication. This "coloring" of speech is critical to the message conveyed, and in some languages is even used to change the literal meaning of the word uttered. These deficiencies, referred to as aprosodias, are associated with right-hemisphere damage to the cortical regions that correspond to Brocas and Wernickes areas and associated regions in the left hemisphere. The aprosodias emphasize that although the left hemisphere figures prominently in the comprehension and production of language for most humans, other regions, including areas in the right hemisphere, are needed to generate the full richness of everyday speech. .8 Signing deficits in congenitally deaf individuals who had learned sign language from birth and later suffered lesions of the language areas in the left hemisphere. Left hemisphere damage produced signing problems in these patients analogous to the aphasias seen after comparable lesions in hearing, speaking patients. In this example, the patient is expressing the sentence "We arrived in Jerusalem and stayed there." Compared to a normal control, he cannot properly control the spatial orientation of the signs. The direction of the correct signs and the aberrant direction of the "aphasic" signs are indicated in the upper left-hand corner of each panel.The implication of at least some aspects of the foregoing account is that the cortical organization of language does not simply reflect specializations for hearing and speaking the language regions of the brain appear to be more broadly organized for processing symbols pertinent to social communication. Strong support for this conclusion has come from studies of sign language in individuals deaf from birth.American Sign Language has all the components of spoken and heard language. Based on this knowledge, Ursula Bellugi and her colleagues at the Salk Institute examined the cortical localization of sign language abilities in patients who had suffered lesions of either the left or right hemisphere. All these deaf individuals never learned language, had been signing throughout their lives, had deaf spouses, were members of the deaf community, and were right-handed. The patients with left-hemisphere lesions, which in each case involved the language areas of the frontal andor temporal lobes, had measurable deficits in sign production and comprehension when compared to normal signers of similar age A variety of methods have all been used to understand the organization of language in the human brain. This effort began in the nineteenth century by correlating clinical signs and symptoms with the location of brain lesions determined postmortem. In the twentieth century, additional clinical observations together with studies of split-brain patients, mapping at neurosurgery, transient anesthesia of a single hemisphere, and noninvasive imaging techniques such as PET and MRI have greatly extended knowledge about the neural substrates of language. Together, these various approaches show that the perisylvian cortices of the left hemisphere are especially important for normal language in the vast majority of humans. The right hemisphere also contributes importantly to language, most obviously by giving it emotional tone. The similarity of the deficits after comparable brain lesions in congenitally deaf individuals and their speaking counterparts have shown further that the cortical representation of language is independent of the means of its expression or perception. The specialized language areas that have been identified are evidently the major components of a widely distributed set of brain regions that allow humans to communicate effectively by means of symbols that can be attached to objects, concepts and feelings.Sleep-which is defined behaviorally by the normal suspension of consciousness and electrophysiologically by specific brain wave criteria-consumes fully a third of our lives. Sleep occurs in all mammals, and probably in all vertebrates. We crave sleep when deprived of it and, to judge from some animal studies, continued sleep deprivation can ultimately be fatal. Surprisingly, however, this peculiar state is not the result of a simple diminution of brain activity for example, in REM sleep, the brain is about as active as it is when people are awake. Rather, sleep is a series of precisely controlled brain states, the sequence of which is governed by a group of brainstem nuclei that project widely throughout the brain and spinal cord. The reason for such high levels of brain activity during REM sleep, the significance of dreaming, and the basis of the restorative effect of sleep are all topics that remain poorly understood. The clinical importance of sleep is obvious from the prevalence of sleep disorders. In any given year about 40 million Americans suffer from chronic sleep disorders, and an additional 30 million experience occasional sleeping problems that are severe enough to interfere with their daily activities.To feel rested and refreshed upon awakening, most adults require 7-8 hours of sleep, although this number varies among individuals Sleep is a highly conserved behavior that occurs in animals ranging from fruit flies to humans. Despite this prevalence, why we sleep is not well understood. Since an animal is particularly vulnerable while sleeping, there must be evolutionary advantages that outweigh this considerable disadvantage. Shakespearecalled sleep "natures soft nurse," emphasizing the restorative nature of sleep. From a perspective of energy conservation, one function of sleep is to replenish brain glycogen levels, which fall during the waking hours. In addition, since it is generally colder at night, more energy would have to be expended to keep warm were we nocturnally active. Body temperature has a 24-hour cycle, reaching a minimum at night and thus reducing heat loss Whatever the reasons for sleeping, in mammals sleep is evidently necessary for survival. Sleep-deprived rats lose weight despite increasing food intake and progressively fail to regulate body temperature as their core temperature increases several degrees. They also develop infections, suggesting some compromise of the immune system. Rats completely deprived of sleep .2 Circadian rhythmicity of core body temperature, and of growth hormone and cortisol levels in the blood. In the early evening, core temperature begins to decrease whereas growth hormone begins to increase. The level of cortisol, which reflects stress, begins to increase in the morning and stays elevated for several hours.die within a few weeks A wide variety of animals have a rest-activity cycle that often occurs in a daily rhythm. Even among mammals, however, the organization of sleep depends very much on the species in question. As a general rule, predatory animals can indulge, as humans do, in long, uninterrupted periods of sleep that can be nocturnal or diurnal, depending on the time of day when the animal acquires food, mates, cares for its young, and deals with lifes other necessities. The survival of animals that are preyed upon, however, depends much more critically on continued vigilance. Such species-as diverse as rabbits and giraffes-sleep during short intervals that usually last no more than a few minutes. Shrews, the smallest mammals, hardly sleep at all.An especially remarkable solution to the problem of maintaining vigilance during sleep is shown by dolphins and seals, in whom sleep alternates between the two cerebral hemispheres Human sleep occurs with circadian periodicity, and biologists interested in circadian rhythms have explored a number of questions about this daily cycle. What happens, for example, when individuals are prevented from sensing the cues they normally use to distinguish night and day This question has been addressed by placing volunteers in an environment such as a cave or bunker that lacks external time cues Activation of the SCN evokes responses in neurons whose axons first synapse in the paraventricular nucleus of the hypothalamus and descend to the preganglionic sympathetic neurons in intermediolateral zone in the lateral horns of the thoracic spinal cord. As described in Chapter 20, these pregan-glionic neurons modulate neurons in the superior cervical ganglia whose postganglionic axons project to the pineal gland in the midline near the dorsal thalamus Most sleep researchers consider the superior chiasmatic nucleus to be the "master clock." Evidence for this conclusion is that its removal of the SCN in experimental animals abolishes their circadian rhythm of sleep and waking. Furthermore, when SCN cells are placed in organ culture, they exhibit characteristic circadian rhythms. The SCN also governs other functions that are synchronized with the sleep-wake cycle, including body temperature, hormone secretion, blood pressure, and urine production The normal cycle of human sleep and wakefulness implies that, at specific times, various neural systems are being activated while others are being turned off. For centuries-indeed up until the 1950s-most people who thought about sleep considered it a unitary phenomenon whose physiology was essentially passive and whose purpose was simply restorative. In 1953, however, Nathaniel Kleitman and Eugene Aserinksy showed, by means of electroencephalographic recordings from normal subjects, that sleep actually comprises different stages that occur in a characteristic sequence.Over the first hour after retiring, humans descend into successive stages of sleep Virtually all plants and animals adjust their physiology and behavior to the 24-hour day-night cycle under the governance of circadian clocks. Molecular biological studies have now indicated much about the genes and proteins that make up the machinery of these clocks, a story that began about 30 years ago. In the early 1970s, Ron Konopka and Seymour Benzer, working at the California Institute of Technology, discovered three mutant strains of fruit flies whose circadian rhythms were abnormal. Further analysis showed the mutants to be alleles of a single locus, which Konopka and Benzer called the period or per gene. In the absence of normal environmental cues, wild-type flies have periods of activity geared to a 24-hour cycle per s mutants have 19 hour rhythms, per 1 mutants have 29-hour rhythms, and per 0 mutants have no apparent rhythm.About 10 years later, Michael Young at Rockefeller University and Jeffrey Hall and Michael Rosbash at Brandeis University independently cloned the first of the three per genes. Cloning a gene does not necessarily reveal its function, however, and so it was in this case. Nonetheless, the gene product Per, a nuclear protein, is found in many Drosophila cells pertinent to the production of the flys circadian rhythms. Moreover, normal flies show a circadian variation in the amount of per mRNA and Per protein, whereas per 0 flies, which lack a circadian rhythm, do not show this circadian rhythmicity of gene expression. high-frequency spike clusters called sleep spindles. Sleep spindles are periodic bursts of activity at about 10-12 Hz that generally last 1-2 seconds and arise as a result of interactions between thalamic and cortical neurons. In stage III sleep, which represents moderate to deep sleep, the number of spindles decreases, whereas the amplitude of the EEG activity increases further and the frequency continues to fall. In the deepest level of sleep, stage IV sleep, also known as slow-wave sleep, the predominant EEG activity consists of very low frequency, high-amplitude fluctuations called delta waves, the characteristic slow waves for which this phase of sleep is named. The entire sequence from drowsiness to deep stage IV sleep usually takes about an hour. These four sleep stages are called non-rapid eye movement sleep, and its most prominent feature is slow-wave sleep. It is more difficult to awaken people from slow-wave sleep, which is therefore considered to be the deepest stage of sleep. Following a period of slow-wave sleep, however, EEG recordings show that the stages of sleep reverse, entering a quite different state called rapid eye movement sleep. In REM sleep, EEG recordings are remarkably similar to those of the awake state At the start of the day, the transcription of Clk and Bmal1 commencences, and the proteins CLOCK and BMAL1 are synthesized in tandem. When the concentrations of C and B increase sufficiently, they associate as dimers and bind to regulatory DNA sequences that act as a circadian transcriptional enhancers of the genes Cry, Per1, Per2, Per3, and CCG. As a result, the proteins PER1, 2, and 3, CRY, and proteins such as VP are produced. These proteins then diffuse from the nucleus into the cytoplasm, where they are modified.Although the functions of PER1 and PER3 remain to be elucidated, when the cytoplasmic concentrations of PER2 and CRY increase, they associate as CRY-PER2, and diffuse back into the nucleus. Here, PER2 stimulates the synthesis of C, and B, and CRY binds to C-B dimers, inhibiting their ability to stimulate the synthesis of the other genes. The complete time course of these feedback loops is 24 hours.Although electrical activity recorded from the exposed cerebral cortex of a monkey was reported in 1875, it was not until 1929 that Hans Berger, a psychiatrist at the University of Jena, first made scalp recordings of this activity in humans. Since then, the electroencephalogram, or EEG, has received mixed press, touted by some as a unique opportunity to understand human thinking and denigrated by others as too complex and poorly resolved to allow anything more than a superficial glimpse of what the brain is actually doing. The truth lies somewhere in between. Certainly no one disputes that electroencephalography has provided a valuable tool to both researchers and clinicians, particularly in the fields of sleep physiology and epilepsy.The major advantage of electroencephalography, which involves the application of a set of electrodes to standard positions on the scalp The cortical origin of EEG activity has been clarified by animal studies, which have shown that the source of the current that causes the fluctuating scalp potential is primarily the pyramidal neurons and their synaptic connections in the deeper layers of the cortex Despite these intriguing observations, the functional significance of these cortical rhythms is not known. The purpose of the brains remarkable oscillatory activity is a puzzle that has defied electroencephalographers and neurobiologists for more than 60 years. again in the second round of this continuing cycling, but generally not during the rest of the night In summary, the typical 8 hours of sleep experienced each night actually comprise several cycles that alternate between non-REM and REM sleep, and the brain is quite active during much of this supposedly dormant, restful time. The amount of daily REM sleep decreases from about 8 hours at birth to 2 hours at 20 years to only about 45 minutes at 70 years of age A variety of additional physiological changes take place during the different stages of sleep Despite the similarity of EEG recordings obtained in REM sleep and in wakefulness, the two conditions are clearly not equivalent brain states. REM sleep is characterized by dreaming, which entails a sort of visual hallucination, often characterized by increased emotion and a lack of self-reflection and volitional control. Since most muscles are inactive during REM sleep, the motor responses to dreams are relatively minor. The relative physical paralysis during REM sleep arises from increased activity in GABAergic neurons in the pontine reticular formation that project to inhibitory neurons that synapse in turn with lower motor neurons in the spinal cord Despite this wealth of descriptive information about the stages of sleep and an intense research effort, the functional purposes of the various sleep states remain poorly understood. Whereas most sleep researchers accept the idea that the purpose of non-REM sleep is at least in part restorative, the function of REM sleep remains a matter of considerable controversy.A possible clue about the purposes of REM sleep is the prevalence of dreams during these epochs of the sleep cycle. The time of occurrence of dreams during sleep was determined by waking volunteers during either non-REM or REM sleep and asking them if they were dreaming. Subjects awakened from REM sleep usually recalled elaborate, vivid and emotional dreams subjects awakened during non-REM sleep reported fewer dreams, which, when they did occur, were more conceptual, less vivid, and less emo- tion-laden. Thus dreaming can also occur during light non-REM sleep, near the onset of sleep and before awakening. Dreams have been studied in a variety of ways, perhaps most notably within the psychoanalytic framework aimed at revealing unconscious thought processes considered to be at the root of neuroses. Sigmund Freuds The Interpretation of Dreams, published in 1900, speaks eloquently to the complex relationship between conscious and unconscious mentation. Specifically, Freud thought that during dreaming the "ego" relaxes its hold on the "id," or subconscious. For the most part, these ideas are now out of fashion, but to give Freud his due, at the time he made these speculations little was known about neurobiology of the brain in general and sleep in particular.Since Freuds time, several other explanations of dreams have been proposed. One idea is that dreaming releases behaviors less commonly entertained in the waking state. Studies have found that about 60% of dream content is associated with sadness, apprehension, or anger 20% with happiness or excitement and only 10% with sexual feelings or acts. Another suggestion is that dreaming evolved to dispose of unwanted memories that accumulate during the day. A further plausible idea about the function of dreams is that they help consolidate learned tasks, perhaps by strengthening synaptic activity associated  with recent experiences. This hypothesis is supported by studies of remembered spatial location in rodents, and by experiments in humans that show a sleep-dependent improvement in learning. However, some experts, such as Allan Hobson, take the more skeptical view that dream content may be "as much dross as gold, as much cognitive trash as treasure, as much informational noise as a signal of something." Nevertheless, most people, including most sleep researchers, at least privately give some credence to the significance of dream content.Adding to this uncertainty about the purposes of REM sleep and dreaming is the fact that depriving human subjects of REM sleep for as much as two weeks has little or no obvious effect on their behavior. The apparent innocuousness of REM sleep deprivation contrasts markedly with the devastating effects of total sleep deprivation mentioned earlier. The implication of these findings is that we can get along without REM sleep but need non-REM sleep in order to survive. In summary, the questions of why we have REM sleep and why we dream basically remain unanswered.From the descriptions of the various physiological states that occur during sleep, it is clear that periodic charges in the balance of excitation and inhibition must occur in many neural circuits. What follows is a brief overview of these incompletely understood circuits and the interactions among them that govern sleeping and wakefulness.In 1949, Horace Magoun and Giuseppe Moruzzi provided one of the first clues about the circuits involved in the sleep-wake cycle. They found that electrically stimulating a group of cholinergic neurons near the junction of the pons and midbrain causes a state of wakefulness and arousal. This region of the brainstem was given the name reticular activating system The saccade-like eye movements that define REM sleep arise because, in the absence of external visual stimuli, endogenously generated signals from As the text explains, the mechanisms of sleep and wakefulness determine mental status at any moment on a continuum that normally ranges from stage IV sleep to high alert. There is, however, another way that "wakefulness" has been considered, namely from the perspective of consciousness as such. Although the brainstem circuits and projections supporting consciousness are beginning to be understood, these neurological aspects of consciousness are-not surprisinglyinsufficient to satisfy philosophers, theologians, and neuroscientists interested in the broader issues that the phenomenon of consciousness raises. The common concern of these diverse groups is the more general basis of selfawareness, in particular whether other animals have this mental property and whether machines could ever be selfaware in the way humans are. With respect to the first of these issues, despite a longstanding debate about consciousness in other animals, it would be foolish to assert that humans are alone in possessing this obviously useful biological attribute. However, from a purely logical vantage it is impossible, strictly speaking, to know whether any being other than ourselves is conscious as philosophers have long pointed out, we must inevitably take the consciousness of others on faith.Nonetheless, it is reasonable to assume that animals with brains structured much like ours have in some measure the same ability to be self-aware as we do. The ability to reflect on the past and plan for the future that is made possible by self-awareness is surely an advantage that evolution would have to some degree inculcated in the very similar brains of higher primates. At what phylogenetic level this assumption about self-awareness falls below the definition of consciousness as we know it in ourselves is, of course, unclear. But a reasonable supposition would be that consciousness is present in animals in proportion to the complexity of their brains and behaviors-particularly those behaviors that are sophisticated enough to benefit from reflecting on past outcomes and future eventualities.The question of whether machines can ever be conscious is a much more contentious issue, but is also subject to common sense informed by some knowledge of how brains work. If one rejects dualism, it follows that a structure could be built by sufficiently wise agents that either mimicked our own consciousness by being effectively isomorphic with brains, or achieved consciousness using physically different elements in sufficiently biological ways to allow self-awareness.There are, of course, some caveats. An interesting argument in this respect was put forward by the philosopher John Searle to rebut those who imagine that present-day computers, because their operations in some ways resemble mental processes, can already be considered to have the rudiments of consciousness. His famous "Chinese Room" analogy describes a cubicle in which workers are handed English letters that they then translate into Chinese characters. The workers themselves have no knowledge of English or Chinese, but simply a set of rules that enables the characters to be efficiently translated. The output of the room is sensible statements in Chinese. Yet the workers have no knowledge of the meaning of the information they are dealing with or of the rooms larger purpose. Searle uses this image to emphasize that meaningful output from a computer, however sophisticated, cannot provide evidence for consciousness or self-awareness within it. Despite this clever argument deflating simplistic assertions that extant machines exhibit a rudimentary form of consciousness, Searle does not dispute the notion that nothing in principle stands in the way of constructing conscious entities.A great deal of literature on the subject notwithstanding, these fascinating questions about consciousness are not readily subject to neurobiological investigation. Although a number of contemporary scientists have advocated the idea that neurobiology will soon reveal the "basis" of consciousness, such revelations are not likely. A more plausible scenario is that as information grows about the nature of other animals, about computers, and indeed about the brain, the question "What is consciousness" may simply fade from center stage in much the same way that the question "What is life" was asked less and less frequently as biologists and others recognized it as an ill-posed problem that admitted no definite answer. the pontine reticular formation are transmitted to the motor region of the superior colliculus. As described in Chapter 19, collicular neurons project to the paramedialpontine reticular formation and the rostral interstitial nucleus, which coordinates timing and direction of eye movements. REM sleep is also characterized by EEG waves that originate in the pontine reticular formation and propagate through the lateral geniculate nucleus of the thalamus to the occipital cortex. These pontine-geniculo-occipital waves provide a useful marker for the beginning of REM sleep they also indicate yet another neural network by which brainstem nuclei can activate the cortex.Human fMRI and PET studies have been used to compare brain activity in the awake state and in REM sleep, as well as the phenomenon of consciousness more generally. Activity in the amygdala, parahippocampus, pontine tegmentum, and anterior cingulate cortex all increase in REM sleep, whereas activity in the dorsolateral prefrontal and posterior cingulate cortices decreases The oscillatory state of thalamocortical neurons can be transformed into the tonically active state by activity in the cholinergic or monoaminergic projections from the brainstem nuclei It is generally agreed that a key component of the reticular activating system is a group of cholinergic nuclei near the pons-midbrain junction that project to thalamocortical neurons Activity of these neurons is not, however, the only neuronal basis of wakefulness also involved are the noradrenergic neurons of the locus coeruleus the serotonergic neurons of the raphe nuclei and the histaminecontaining neurons in the tuberomammillary nucleus of the hypothalamus The three circuits responsible for the awake state are periodically inhibited by neurons in the ventrolateral preoptic nucleus of the hypothalamus These complex interactions and effects are summarized in The effects of brainstem nuclei on mental status are achieved by modulating the rhythmicity of interactions between the thalamus and the cortex. Thus, the activity of several ascending systems from the brainstem decreases both the rhythmic bursting of the thalamocortical neurons and the related synchronized activity of cortical neurons.To appreciate how different sleep states reflect modulation of thalamocortical activity, it is useful to consider the electrophysiological responses of the relevant neurons. Thalamocortical neurons receive ascending projections from the locus coeruleus, raphe nuclei, reticular activating system, TMN and, as their name implies, project to cortical pyramidal cells. The primary characteristic of thalamocortical neurons is that they can be in one of two stable electrophysiological states 